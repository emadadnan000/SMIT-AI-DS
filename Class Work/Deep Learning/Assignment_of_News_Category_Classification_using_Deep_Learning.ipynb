{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# News Category Classification using Deep Learning (Reuters Dataset)\n",
        "\n",
        "\n",
        "## üéØ Objective\n",
        "\n",
        "In this lecture, we will build a Deep Learning model that classifies news articles into different categories using the Reuters dataset (available in Keras).\n",
        "\n",
        "This project helps students learn multi-class text classification, an important step after binary classification like sentiment analysis.\n",
        "\n",
        "## üß© Theoretical Background\n",
        "üîπ What is Text Classification?\n",
        "\n",
        "Text classification automatically assigns categories or labels to text.\n",
        "Examples:\n",
        "\n",
        "Classify news articles as politics, sports, business\n",
        "\n",
        "Detect spam or not spam emails\n",
        "\n",
        "Categorize customer support tickets\n",
        "\n",
        "üîπ Dataset: Reuters Newswire Topics\n",
        "\n",
        "Keras provides this dataset via:\n",
        "\n"
      ],
      "metadata": {
        "id": "L-QlCnI4G6KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import reuters"
      ],
      "metadata": {
        "id": "FMv1sxhdG-Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It contains 11,228 articles and 46 categories, already tokenized (each word is represented by an integer).\n",
        "\n",
        "üîπ Why Deep Learning?\n",
        "\n",
        "Deep learning automatically learns patterns from sequences of text no manual feature extraction required."
      ],
      "metadata": {
        "id": "XefUcFXTHukI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "IccHth46HwwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "\n",
        "reuters: Loads the Reuters dataset\n",
        "\n",
        "Embedding: Converts word indices to dense vectors\n",
        "\n",
        "LSTM: Learns sequential dependencies\n",
        "\n",
        "Dense: Fully connected layer for classification\n",
        "\n",
        "pad_sequences: Makes all text inputs of equal length\n",
        "\n",
        "to_categorical: Converts labels to one-hot format\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9MWhByrTH5hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Example article:\", X_train[0][:10])\n",
        "print(\"Label:\", y_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7T9-SimIJNl",
        "outputId": "b926e35f-4714-4dcc-d5f0-712670394f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training samples: 8982\n",
            "Testing samples: 2246\n",
            "Example article: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207]\n",
            "Label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "We load only the top 10,000 most frequent words for efficiency.\n",
        "Each article is stored as a list of integers representing words.\n",
        "The labels correspond to 46 possible categories."
      ],
      "metadata": {
        "id": "euQw6KOYIQYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 200\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "print(\"Shape of training data:\", X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnM--IoZIRQH",
        "outputId": "cbf12b65-de84-4b10-9db4-5d8c60c9382c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (8982, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "All news articles are padded or truncated to 200 words for consistent LSTM input shape.\n",
        "This ensures that every input sequence is the same size."
      ],
      "metadata": {
        "id": "-wFiF1R1IaoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print(\"Shape of labels:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skGLtO5jIbGk",
        "outputId": "c8540619-88ab-4390-a582-9381f1961ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of labels: (8982, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "Because there are 46 output categories, we use one-hot encoding ‚Äî each label becomes a vector of size 46, where only one element is 1."
      ],
      "metadata": {
        "id": "wtM0FmfGIqq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(10000, 64, input_length=max_len),\n",
        "    LSTM(128, dropout=0.3, recurrent_dropout=0.3),\n",
        "    Dense(46, activation='softmax'),\n",
        "    Dense(64, activation='relu')\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrfIRM_7It7H",
        "outputId": "8b193319-955c-432b-d00d-389d1dd91d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Sequential' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3348598513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "\n",
        "Embedding(10000, 64): Converts word indices to dense 64-dimensional vectors.\n",
        "\n",
        "LSTM(64): Learns relationships between words in sequence.\n",
        "\n",
        "Dense(46, activation='softmax'): Produces probabilities for 46 classes.\n",
        "\n",
        "‚öôÔ∏è Why Softmax Activation?\n",
        "\n",
        "Softmax converts outputs into probabilities that sum to 1, making it ideal for multi-class classification."
      ],
      "metadata": {
        "id": "NUzU9I9tI0aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "DNtZDWITJATz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "\n",
        "Optimizer: Adam ‚Äî adjusts learning rate automatically for faster convergence.\n",
        "\n",
        "Loss: categorical_crossentropy ‚Äî suitable for more than 2 classes.\n",
        "\n",
        "Metric: accuracy ‚Äî to measure correct classifications.\n",
        "\n",
        "‚öôÔ∏è Why Categorical Crossentropy Loss?\n",
        "\n",
        "It measures how well predicted probabilities match the true labels."
      ],
      "metadata": {
        "id": "nKuodK9SJJkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9qHaqpaJKRy",
        "outputId": "1e47cf2b-96e6-4df3-a8eb-c76a73234645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 399ms/step - accuracy: 0.3318 - loss: 3.1385 - val_accuracy: 0.3620 - val_loss: 2.3635\n",
            "Epoch 2/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "We train the model for 5 epochs ‚Äî meaning it goes through the entire dataset 5 times.\n",
        "Validation data allows us to track overfitting and generalization performance."
      ],
      "metadata": {
        "id": "4ET5j9cJJTp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Task #1 (With Solution)\n",
        "\n",
        "üëâ Task: Train the model for 8 epochs instead of 5 and compare accuracy."
      ],
      "metadata": {
        "id": "SUwgR9pLJY08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_8 = model.fit(X_train, y_train,\n",
        "                      epochs=8,\n",
        "                      batch_size=128,\n",
        "                      validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "EnST_8hWJZkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Observation:\n",
        "As epochs increase, accuracy may improve slightly, but if validation accuracy stops improving ‚Äî the model starts overfitting."
      ],
      "metadata": {
        "id": "yu_r56Y_JhIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "t14C-bcWJhlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "The test accuracy shows how well the model performs on unseen data.\n",
        "Accuracy around 75‚Äì80% is typical for this dataset."
      ],
      "metadata": {
        "id": "xWQPgy8MJldI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test[:5])\n",
        "print(\"Predicted categories:\", predictions.argmax(axis=1))\n"
      ],
      "metadata": {
        "id": "R5Bhp6YnJsH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Explanation:\n",
        "model.predict() gives probabilities for each class.\n",
        "argmax(axis=1) returns the index (category) with the highest probability."
      ],
      "metadata": {
        "id": "kNJ7o9mTJyWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Tasks (Without Solutions)\n"
      ],
      "metadata": {
        "id": "-RRfuBfJkk22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1Ô∏è‚É£ Replace LSTM(64) with LSTM(128) and compare accuracy.\n",
        "\n",
        "2Ô∏è‚É£ Add another hidden layer:\n",
        "\n",
        "```\n",
        "Dense(64, activation='relu')\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "PwM95lq6KBKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "before the final output layer.\n",
        "\n",
        "3Ô∏è‚É£ Change optimizer from 'adam' to 'rmsprop' and observe how it affects training speed or accuracy."
      ],
      "metadata": {
        "id": "XDtm0W2cKV59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üè† Mini Project (Home Assignment)\n",
        "üéØ Project: Topic Classification of News Headlines\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Use the 20 Newsgroups dataset from:"
      ],
      "metadata": {
        "id": "fIJ_l73HKcd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "metadata": {
        "id": "AVfOVQcOKdS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tokenize and pad the text similar to this project.\n",
        "\n",
        "* Build a deep learning model using Embedding + LSTM + Dense layers.\n",
        "\n",
        "* Compare two models:\n",
        "\n",
        "* One with only Dense layers\n",
        "\n",
        "* One with LSTM layers\n",
        "\n",
        "Submit:\n",
        "\n",
        "Your notebook\n"
      ],
      "metadata": {
        "id": "XyF_aVPZKh7j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lY39YF7SK0tZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}