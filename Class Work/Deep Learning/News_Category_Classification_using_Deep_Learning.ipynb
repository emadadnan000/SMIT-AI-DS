{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-QlCnI4G6KU"
      },
      "source": [
        "# News Category Classification using Deep Learning (Reuters Dataset)\n",
        "\n",
        "\n",
        "## ğŸ¯ Objective\n",
        "\n",
        "In this lecture, we will build a Deep Learning model that classifies news articles into different categories using the Reuters dataset (available in Keras).\n",
        "\n",
        "This project helps students learn multi-class text classification, an important step after binary classification like sentiment analysis.\n",
        "\n",
        "## ğŸ§© Theoretical Background\n",
        "ğŸ”¹ What is Text Classification?\n",
        "\n",
        "Text classification automatically assigns categories or labels to text.\n",
        "Examples:\n",
        "\n",
        "Classify news articles as politics, sports, business\n",
        "\n",
        "Detect spam or not spam emails\n",
        "\n",
        "Categorize customer support tickets\n",
        "\n",
        "ğŸ”¹ Dataset: Reuters Newswire Topics\n",
        "\n",
        "Keras provides this dataset via:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMv1sxhdG-Eg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import reuters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XefUcFXTHukI"
      },
      "source": [
        "It contains 11,228 articles and 46 categories, already tokenized (each word is represented by an integer).\n",
        "\n",
        "ğŸ”¹ Why Deep Learning?\n",
        "\n",
        "Deep learning automatically learns patterns from sequences of text no manual feature extraction required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IccHth46HwwN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWhByrTH5hH"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "\n",
        "reuters: Loads the Reuters dataset\n",
        "\n",
        "Embedding: Converts word indices to dense vectors\n",
        "\n",
        "LSTM: Learns sequential dependencies\n",
        "\n",
        "Dense: Fully connected layer for classification\n",
        "\n",
        "pad_sequences: Makes all text inputs of equal length\n",
        "\n",
        "to_categorical: Converts labels to one-hot format\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7T9-SimIJNl",
        "outputId": "f645ac3b-8a23-47ba-8ab5-75fdeed1e8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training samples: 8982\n",
            "Testing samples: 2246\n",
            "Example article: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207]\n",
            "Label: 3\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n",
        "print(\"Example article:\", X_train[0][:10])\n",
        "print(\"Label:\", y_train[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQw6KOYIQYO"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "We load only the top 10,000 most frequent words for efficiency.\n",
        "Each article is stored as a list of integers representing words.\n",
        "The labels correspond to 46 possible categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnM--IoZIRQH",
        "outputId": "0c71fbc9-a4c6-4ecb-d41d-150998814b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training data: (8982, 200)\n"
          ]
        }
      ],
      "source": [
        "max_len = 200\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "print(\"Shape of training data:\", X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wFiF1R1IaoC"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "All news articles are padded or truncated to 200 words for consistent LSTM input shape.\n",
        "This ensures that every input sequence is the same size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skGLtO5jIbGk",
        "outputId": "14f1a199-ccf6-44d8-9a9a-f67f22947b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of labels: (8982, 46)\n"
          ]
        }
      ],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print(\"Shape of labels:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtM0FmfGIqq0"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "Because there are 46 output categories, we use one-hot encoding â€” each label becomes a vector of size 46, where only one element is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrfIRM_7It7H",
        "outputId": "53de61c4-e3c3-4321-cb0a-571e13d08286"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(10000, 64, input_length=max_len),\n",
        "    LSTM(64, dropout=0.3, recurrent_dropout=0.3),\n",
        "    Dense(46, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUzU9I9tI0aT"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "\n",
        "Embedding(10000, 64): Converts word indices to dense 64-dimensional vectors.\n",
        "\n",
        "LSTM(64): Learns relationships between words in sequence.\n",
        "\n",
        "Dense(46, activation='softmax'): Produces probabilities for 46 classes.\n",
        "\n",
        "âš™ï¸ Why Softmax Activation?\n",
        "\n",
        "Softmax converts outputs into probabilities that sum to 1, making it ideal for multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNtZDWITJATz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKuodK9SJJkz"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "\n",
        "Optimizer: Adam â€” adjusts learning rate automatically for faster convergence.\n",
        "\n",
        "Loss: categorical_crossentropy â€” suitable for more than 2 classes.\n",
        "\n",
        "Metric: accuracy â€” to measure correct classifications.\n",
        "\n",
        "âš™ï¸ Why Categorical Crossentropy Loss?\n",
        "\n",
        "It measures how well predicted probabilities match the true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9qHaqpaJKRy",
        "outputId": "c7f6c994-aa18-4481-daaf-bbe9fa386065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 352ms/step - accuracy: 0.3106 - loss: 3.2039 - val_accuracy: 0.3620 - val_loss: 2.4192\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 344ms/step - accuracy: 0.3491 - loss: 2.4167 - val_accuracy: 0.4243 - val_loss: 2.2387\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 344ms/step - accuracy: 0.4248 - loss: 2.1706 - val_accuracy: 0.4840 - val_loss: 1.9360\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 343ms/step - accuracy: 0.4934 - loss: 1.9144 - val_accuracy: 0.5218 - val_loss: 2.0297\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 345ms/step - accuracy: 0.5320 - loss: 1.8711 - val_accuracy: 0.5614 - val_loss: 1.7410\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ET5j9cJJTp9"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "We train the model for 5 epochs â€” meaning it goes through the entire dataset 5 times.\n",
        "Validation data allows us to track overfitting and generalization performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUwgR9pLJY08"
      },
      "source": [
        "Class Task #1 (With Solution)\n",
        "\n",
        "ğŸ‘‰ Task: Train the model for 8 epochs instead of 5 and compare accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnST_8hWJZkZ",
        "outputId": "236e6c8b-e771-45ef-a6b7-ff32f6a9d50e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 351ms/step - accuracy: 0.5544 - loss: 1.7029 - val_accuracy: 0.5530 - val_loss: 1.7150\n",
            "Epoch 2/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 344ms/step - accuracy: 0.5629 - loss: 1.6726 - val_accuracy: 0.5784 - val_loss: 1.6738\n",
            "Epoch 3/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 347ms/step - accuracy: 0.5686 - loss: 1.6503 - val_accuracy: 0.5681 - val_loss: 1.6599\n",
            "Epoch 4/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 351ms/step - accuracy: 0.5722 - loss: 1.6308 - val_accuracy: 0.5797 - val_loss: 1.6476\n",
            "Epoch 5/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 363ms/step - accuracy: 0.5873 - loss: 1.5792 - val_accuracy: 0.5873 - val_loss: 1.6338\n",
            "Epoch 6/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 345ms/step - accuracy: 0.5919 - loss: 1.5566 - val_accuracy: 0.5926 - val_loss: 1.6127\n",
            "Epoch 7/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 344ms/step - accuracy: 0.6113 - loss: 1.4789 - val_accuracy: 0.5904 - val_loss: 1.6111\n",
            "Epoch 8/8\n",
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 346ms/step - accuracy: 0.6148 - loss: 1.4844 - val_accuracy: 0.5988 - val_loss: 1.6113\n"
          ]
        }
      ],
      "source": [
        "history_8 = model.fit(X_train, y_train,\n",
        "                      epochs=8,\n",
        "                      batch_size=128,\n",
        "                      validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu_r56Y_JhIe"
      },
      "source": [
        "ğŸ’¡ Observation:\n",
        "As epochs increase, accuracy may improve slightly, but if validation accuracy stops improving â€” the model starts overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t14C-bcWJhlo",
        "outputId": "5eb8d4c1-e8e6-43ce-f6fc-1d176d4fdb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6074 - loss: 1.5845\n",
            "Test Accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWQPgy8MJldI"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "The test accuracy shows how well the model performs on unseen data.\n",
        "Accuracy around 75â€“80% is typical for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Bhp6YnJsH4",
        "outputId": "21ebe27e-0ef3-4aba-e5f1-fab249d13fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n",
            "Predicted categories: [ 3 16 19  4 19]\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(X_test[:5])\n",
        "print(\"Predicted categories:\", predictions.argmax(axis=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNJ7o9mTJyWl"
      },
      "source": [
        "ğŸ§¾ Explanation:\n",
        "model.predict() gives probabilities for each class.\n",
        "argmax(axis=1) returns the index (category) with the highest probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwM95lq6KBKd"
      },
      "source": [
        "Class Tasks (Without Solutions)\n",
        "\n",
        "1ï¸âƒ£ Replace LSTM(64) with LSTM(128) and compare accuracy.\n",
        "\n",
        "2ï¸âƒ£ Add another hidden layer:\n",
        "\n",
        "```\n",
        "Dense(64, activation='relu')\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDtm0W2cKV59"
      },
      "source": [
        "before the final output layer.\n",
        "\n",
        "3ï¸âƒ£ Change optimizer from 'adam' to 'rmsprop' and observe how it affects training speed or accuracy."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
