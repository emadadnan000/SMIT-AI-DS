{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "BF0CRiL6-Wgd",
      "metadata": {
        "id": "BF0CRiL6-Wgd"
      },
      "source": [
        "# ğŸ¯ Sentiment Analysis on Movie Reviews (NLP Project)\n",
        "---\n",
        "### ğŸ§  Objective\n",
        "The goal of this project is to build a **Deep Learning model** that can understand the sentiment (Positive or Negative) of a **movie review** written in text form.\n",
        "\n",
        "We will use the **IMDb Movie Reviews Dataset**, which is readily available in Keras.\n",
        "\n",
        "This notebook includes:\n",
        "- Theoretical explanations\n",
        "- Practical implementation\n",
        "- Explanations for activation and loss functions\n",
        "- Class tasks with and without solutions\n",
        "- A final home assignment project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81vw4-ZT-Wgh",
      "metadata": {
        "id": "81vw4-ZT-Wgh"
      },
      "source": [
        "## ğŸ”¹ Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "VVeKsS-K-Wgi",
      "metadata": {
        "id": "VVeKsS-K-Wgi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j4o7SQf5-Wgk",
      "metadata": {
        "id": "j4o7SQf5-Wgk"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- `tensorflow` is our deep learning library.\n",
        "- `imdb` loads a preprocessed dataset of movie reviews.\n",
        "- `pad_sequences` ensures all text reviews are the same length for training.\n",
        "- `Embedding` converts words into meaningful numeric vectors.\n",
        "- `LSTM` is used to capture the sequence and context of the text.\n",
        "- `Dense` layer is used for the final classification output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pod_mPzA-Wgk",
      "metadata": {
        "id": "Pod_mPzA-Wgk"
      },
      "source": [
        "## ğŸ”¹ Step 2: Load and Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ZLW06Egy-Wgl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLW06Egy-Wgl",
        "outputId": "33e87ce8-f800-4c93-acb3-3a20c81f1d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Training samples: 25000\n",
            "Testing samples: 25000\n",
            "Example review: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
            "Label (0=Negative, 1=Positive): 1\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "print('Training samples:', len(X_train))\n",
        "print('Testing samples:', len(X_test))\n",
        "print('Example review:', X_train[0][:10])\n",
        "print('Label (0=Negative, 1=Positive):', y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gQWvgLy5-Wgl",
      "metadata": {
        "id": "gQWvgLy5-Wgl"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- The dataset is already tokenized â€” each word is replaced by an integer.\n",
        "- We only use the top 10,000 most frequent words to simplify the model.\n",
        "- Each review is labeled as 0 (negative) or 1 (positive)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0SYRfSmi-Wgl",
      "metadata": {
        "id": "0SYRfSmi-Wgl"
      },
      "source": [
        "## ğŸ”¹ Step 3: Pad Sequences (Make Equal Length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "67iw-W7F-Wgl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67iw-W7F-Wgl",
        "outputId": "ce9b34a7-13de-4dcb-88c8-118151950c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After padding: (25000, 200) (25000, 200)\n"
          ]
        }
      ],
      "source": [
        "max_len = 200\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "print('After padding:', X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4xf90Tic-Wgm",
      "metadata": {
        "id": "4xf90Tic-Wgm"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- Deep learning models expect inputs of the same size.\n",
        "- Short reviews are padded with zeros at the beginning to make them all 200 words long."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "swXMTkGY-Wgm",
      "metadata": {
        "id": "swXMTkGY-Wgm"
      },
      "source": [
        "## ğŸ”¹ Step 4: Build the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "xwBxM8jV-Wgn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "xwBxM8jV-Wgn",
        "outputId": "109eeed5-6a17-40dc-9956-462044723b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(10000, 32, input_length=max_len),\n",
        "    LSTM(64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RYFn6pIo-Wgn",
      "metadata": {
        "id": "RYFn6pIo-Wgn"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- **Embedding(10000, 32):** Converts 10,000 unique words into 32-length vectors.\n",
        "- **LSTM(64):** Learns the sequence patterns in text. LSTM keeps memory of long-term word relations.\n",
        "- **Dense(1, activation='sigmoid'):** Outputs probability (0â€“1) for binary sentiment classification.\n",
        "\n",
        "### âš™ï¸ Why Sigmoid Activation?\n",
        "- Sigmoid converts values into a range between 0 and 1.\n",
        "- Perfect for binary outcomes â€” positive (1) or negative (0).\n",
        "- Formula: Ïƒ(x) = 1 / (1 + e^(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_QomagAS-Wgn",
      "metadata": {
        "id": "_QomagAS-Wgn"
      },
      "source": [
        "## ğŸ”¹ Step 5: Compile the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6slQHkcGfHyb"
      },
      "id": "6slQHkcGfHyb"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "i3TrQtGQ-Wgo",
      "metadata": {
        "id": "i3TrQtGQ-Wgo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v-0GG5Gb-Wgo",
      "metadata": {
        "id": "v-0GG5Gb-Wgo"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- **Optimizer (Adam):** Automatically adjusts learning rate for faster convergence.\n",
        "- **Loss Function (Binary Crossentropy):** Best for two-class problems.\n",
        "- **Metrics:** Accuracy helps monitor model performance during training.\n",
        "\n",
        "### âš™ï¸ Why Binary Crossentropy?\n",
        "- It measures how close predicted probabilities are to actual labels.\n",
        "- Formula: L = -[y log(p) + (1 - y) log(1 - p)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12hGFqRe-Wgo",
      "metadata": {
        "id": "12hGFqRe-Wgo"
      },
      "source": [
        "## ğŸ”¹ Step 6: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "LIbQKTP0-Wgo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIbQKTP0-Wgo",
        "outputId": "22d56a50-7c36-4930-b323-6344e33d1d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 321ms/step - accuracy: 0.8659 - loss: 0.3259 - val_accuracy: 0.8563 - val_loss: 0.3356\n",
            "Epoch 2/3\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 319ms/step - accuracy: 0.9187 - loss: 0.2175 - val_accuracy: 0.8705 - val_loss: 0.3049\n",
            "Epoch 3/3\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 322ms/step - accuracy: 0.9366 - loss: 0.1773 - val_accuracy: 0.8670 - val_loss: 0.3403\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=3, batch_size=128, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ixLiyesC-Wgo",
      "metadata": {
        "id": "ixLiyesC-Wgo"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- **Epochs:** Number of times the model sees the entire dataset.\n",
        "- **Batch Size:** Number of samples processed before updating weights.\n",
        "- **Validation Data:** Used to measure model performance on unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o-b-VzOc-Wgo",
      "metadata": {
        "id": "o-b-VzOc-Wgo"
      },
      "source": [
        "## ğŸ§© Class Task #1 (With Solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "wG2jVzLc-Wgp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG2jVzLc-Wgp",
        "outputId": "45a54a63-66f6-476c-b7c5-bced362a02a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 319ms/step - accuracy: 0.9551 - loss: 0.1340 - val_accuracy: 0.8580 - val_loss: 0.3857\n",
            "Epoch 2/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 320ms/step - accuracy: 0.9602 - loss: 0.1170 - val_accuracy: 0.8592 - val_loss: 0.4178\n",
            "Epoch 3/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 321ms/step - accuracy: 0.9672 - loss: 0.0963 - val_accuracy: 0.8592 - val_loss: 0.4451\n",
            "Epoch 4/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 329ms/step - accuracy: 0.9759 - loss: 0.0758 - val_accuracy: 0.8546 - val_loss: 0.4431\n",
            "Epoch 5/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 326ms/step - accuracy: 0.9826 - loss: 0.0588 - val_accuracy: 0.8472 - val_loss: 0.4790\n"
          ]
        }
      ],
      "source": [
        "history_5 = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ii020pvG-Wgp",
      "metadata": {
        "id": "Ii020pvG-Wgp"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "By increasing epochs from 3 to 5, you allow the model more time to learn.\n",
        "This can slightly improve accuracy but may also cause overfitting if too long."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wZ9YG69J-Wgp",
      "metadata": {
        "id": "wZ9YG69J-Wgp"
      },
      "source": [
        "## ğŸ”¹ Step 7: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "FbJPR2GS-Wgp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbJPR2GS-Wgp",
        "outputId": "0e9699b8-b322-47fc-adfb-ff2d3b39c1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.8480 - loss: 0.4799\n",
            "Test Accuracy: 0.85\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XRyHdImS-Wgp",
      "metadata": {
        "id": "XRyHdImS-Wgp"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "Evaluating on the test set tells us how well the model generalizes to new data.\n",
        "A good accuracy for this dataset is around **85â€“88%**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Du57qg77-Wgp",
      "metadata": {
        "id": "Du57qg77-Wgp"
      },
      "source": [
        "## ğŸ”¹ Step 8: Predict on New Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "u9nvLaB_-Wgp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9nvLaB_-Wgp",
        "outputId": "b3793f85-b79f-4062-86b8-9ccc97c116cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "Predicted sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_index = {v: k for k, v in word_index.items()}\n",
        "\n",
        "def decode_review(encoded_review):\n",
        "    return ' '.join([reverse_index.get(i - 3, '?') for i in encoded_review])\n",
        "\n",
        "sample = X_test[0].reshape(1, -1)\n",
        "prediction = model.predict(sample)\n",
        "print('Predicted sentiment:', 'Positive' if prediction > 0.5 else 'Negative')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ClqzB2R--Wgq",
      "metadata": {
        "id": "ClqzB2R--Wgq"
      },
      "source": [
        "### ğŸ§¾ Explanation:\n",
        "- The model predicts sentiment based on probability output.\n",
        "- If output > 0.5 â†’ Positive review, else Negative."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k9t8UToP-Wgq",
      "metadata": {
        "id": "k9t8UToP-Wgq"
      },
      "source": [
        "## ğŸ§  Class Tasks (Without Solutions)\n",
        "1ï¸âƒ£ Replace LSTM(64) with LSTM(128) and observe the impact.\n",
        "2ï¸âƒ£ Add an extra Dense(64, activation='relu') layer before output.\n",
        "3ï¸âƒ£ Change optimizer from Adam to RMSprop and compare results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8Znm99GR-Wgq",
      "metadata": {
        "id": "8Znm99GR-Wgq"
      },
      "source": [
        "## ğŸ  Mini Project (Home Assignment)\n",
        "### ğŸ¯ Sentiment Analysis on Amazon Product Reviews\n",
        "- Download the **Amazon Fine Food Reviews** dataset from Kaggle.\n",
        "- Preprocess (tokenization, padding).\n",
        "- Build an LSTM model for sentiment classification.\n",
        "- Compare embedding sizes (32 vs 64).\n",
        "- Submit your notebook and analysis report."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}