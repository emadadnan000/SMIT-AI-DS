{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3f0769b7",
      "metadata": {
        "id": "3f0769b7"
      },
      "source": [
        "\n",
        "# ðŸ“˜ Introduction to Generative AI & LangChain\n",
        "\n",
        "## 1. Introduction to Generative AI\n",
        "Generative AI refers to AI systems that create NEW content such as text, images, code, audio, and video. These systems learn patterns from huge datasets and generate human-like creative outputs.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Use Cases of Generative AI\n",
        "- Content generation (posts, ads, captions)\n",
        "- Code generation & debugging\n",
        "- AI tutors and learning assistants\n",
        "- Medical note drafting\n",
        "- Product description generation\n",
        "- Creative image/video generation\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Tech Stack for Generative AI\n",
        "\n",
        "### **Programming Languages**\n",
        "- Python  \n",
        "- JavaScript (Node.js for API applications)\n",
        "\n",
        "### **Core Libraries**\n",
        "| Purpose | Libraries |\n",
        "|--------|-----------|\n",
        "| LLMs | OpenAI, Transformers, Gemini API, llama.cpp |\n",
        "| Image Generation | Diffusers, Stability SDK |\n",
        "| Vector DB | ChromaDB, Pinecone, FAISS, Weaviate |\n",
        "| App Frameworks | FastAPI, Flask, Streamlit, Gradio |\n",
        "| Agents & Workflows | LangChain, LlamaIndex, Haystack |\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Introduction to LangChain\n",
        "LangChain is a framework that simplifies building applications with Large Language Models. It provides:\n",
        "\n",
        "- Prompt templates  \n",
        "- Memory (conversation history)  \n",
        "- Chains  \n",
        "- Agents  \n",
        "- Tools  \n",
        "- RAG systems  \n",
        "- Vector DB integration  \n",
        "\n",
        "LangChain helps you build production-ready AI apps quickly.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ”¥ LangChain Example With Full Explanation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8688fcf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run this cell once)\n",
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9afaed6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9afaed6",
        "outputId": "f2f2aaa9-ffb9-4eb0-c27f-cb07f93a2c02"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain.chains import LLMChain\n",
        "\n",
        "# Step 1: Load the model\n",
        "# This connects to OpenAI's LLM. Replace YOUR_KEY with your API key.\n",
        "llm = ChatOpenAI(api_key=\"YOUR_KEY\", model=\"gpt-4o-mini\") # <<< REPLACE \"YOUR_KEY\" WITH YOUR ACTUAL OPENAI API KEY\n",
        "\n",
        "# Step 2: Create a prompt template with a variable placeholder\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Write a short motivational quote about {topic}\"\n",
        ")\n",
        "\n",
        "# Step 3: Build the chain using LangChain Expression Language (LCEL)\n",
        "# This directly pipes the prompt output to the language model input.\n",
        "chain = prompt | llm\n",
        "\n",
        "# Step 4: Run the chain with user input\n",
        "# Using .invoke() with LCEL, and accessing .content for the generated text.\n",
        "result = chain.invoke({\"topic\": \"success\"})\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33fb30cf",
      "metadata": {
        "id": "33fb30cf"
      },
      "source": [
        "\n",
        "## ðŸ” Detailed Explanation of the Code\n",
        "\n",
        "### **1. Importing Libraries**\n",
        "- `ChatOpenAI` â†’ initializes OpenAI model  \n",
        "- `ChatPromptTemplate` â†’ builds prompts with variables  \n",
        "- `LLMChain` â†’ links the model + prompt into a workflow\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Loading the LLM**\n",
        "```python\n",
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "# Set the API key via environment variable\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR_KEY'  # recommended to set outside the notebook\n",
        "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
        "```\n",
        "This creates the model object.  \n",
        "`model=\"gpt-4o-mini\"` is fast and suitable for small tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Creating a Prompt Template**\n",
        "```python\n",
        "prompt = ChatPromptTemplate.from_template(\"Write a quote about {topic}\")\n",
        "```\n",
        "`{topic}` is dynamically replaced at runtime.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Building the Chain**\n",
        "Combines LLM + prompt.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Running the Chain**\n",
        "```python\n",
        "chain.run({\"topic\": \"success\"})\n",
        "```\n",
        "This sends `success` as input, replacing `{topic}`.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸŽ“ Student Tasks\n",
        "\n",
        "## âœ… Task 1 (With Solution)\n",
        "### **Task:**  \n",
        "Write a LangChain program that generates a poem about any topic.\n",
        "\n",
        "### **Solution:**\n",
        "```python\n",
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR_KEY'\n",
        "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
        "prompt = ChatPromptTemplate.from_template(\"Write a poem about {topic}\")\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "print(chain.run({\"topic\": \"moon\"}))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Task 2 (Without Solution)\n",
        "Create a LangChain program that **summarizes a long paragraph** given by the user.\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Task 3 (Without Solution)\n",
        "Create a LangChain **chatbot that remembers previous messages** (use Memory).\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Task 4 (Without Solution)\n",
        "Build a LangChain program that **explains Python errors** in simple language.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
